{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_ac.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqc9Ms6cAhJsUMkaJ2xVvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kulka193/SpaceInvaders/blob/ac1/pg_ac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3BJjuiwOveq"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3WXoIRJ3o96J",
        "outputId": "20d738e8-5c04-4b71-81c1-18729a5740b4"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1XzzkrUO7_P"
      },
      "source": [
        "import gym\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qgV93SwPDs3"
      },
      "source": [
        "env = gym.make('SpaceInvaders-v0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj9Pl-dsPIkv"
      },
      "source": [
        "action_space = env.action_space.n\n",
        "observation_space_dims = env.observation_space.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQJJkw-dPnMZ",
        "outputId": "7030b8e4-25dc-4391-88da-0a1d9f68e2a1"
      },
      "source": [
        "action_space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8czaEXRfPvUd",
        "outputId": "2936521c-5f3d-43ce-980f-91c453f0a07a"
      },
      "source": [
        "observation_space_dims"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210, 160, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5WpHdQRbV6_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_iR9615-04M"
      },
      "source": [
        "https://github.com/germain-hug/Deep-RL-Keras/blob/master/A2C/agent.py\n",
        "\n",
        "https://keras.io/examples/rl/actor_critic_cartpole\n",
        "\n",
        "https://danieltakeshi.github.io/2018/06/28/a2c-a3c\n",
        "\n",
        "https://github.com/pythonlessons/Reinforcement_Learning/blob/master/09_Pong-v0_A2C/Pong-v0_A2C_TF2.py\n",
        "\n",
        "http://inoryy.com/post/tensorflow2-deep-reinforcement-learning\n",
        "\n",
        "https://cgnicholls.github.io/reinforcement-learning/2017/03/27/a3c.html\n",
        "\n",
        "http://dirko.github.io/Keras-policy-gradient\n",
        "\n",
        "https://github.com/minerva-schools/EnsembleRL/blob/master/REINFORCE.ipynb\n",
        "\n",
        "https://github.com/cgnicholls/reinforcement-learning/blob/master/a3c/agent.py\n",
        "\n",
        "https://gombru.github.io/2018/05/23/cross_entropy_loss/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBB33dsdcHea"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOGF1oVWcJIK"
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "siPt5i__cLJe",
        "outputId": "751ebb9d-7f47-452c-f8cc-e482f5328b97"
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/30/f963996d7efea5a336455a3c727711469280c318e2711e295007dea04d7e/setuptools-52.0.0-py3-none-any.whl (784kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 8.2MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 51.3.3\n",
            "    Uninstalling setuptools-51.3.3:\n",
            "      Successfully uninstalled setuptools-51.3.3\n",
            "Successfully installed setuptools-52.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir6ijUcAQNfp"
      },
      "source": [
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "#from pyvirtualdisplay import Display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQOdkeqTbpam",
        "outputId": "ecf041f9-5d6f-41f4-81bf-2c6003629dd4"
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (51.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IpuTVZobx1X"
      },
      "source": [
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a307pGncvHn"
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf7gYkrUcySk",
        "outputId": "62a4cd7a-1c1d-4a4c-a028-06ca9839a179"
      },
      "source": [
        "!apt-get install python-opengl -y\n",
        "\n",
        "!apt install xvfb -y\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "!pip install piglet\n",
        "\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "import gym\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Collecting piglet\n",
            "  Downloading https://files.pythonhosted.org/packages/11/56/6840e5f45626dc7eb7cd5dff57d11880b3113723b3b7b1fb1fa537855b75/piglet-1.0.0-py2.py3-none-any.whl\n",
            "Collecting piglet-templates\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/1e/49d7e0df9420eeb13a636487b8e606cf099f2ee0793159edd8ffe905125b/piglet_templates-1.1.0-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (20.3.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.1.1)\n",
            "Collecting Parsley\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/d6/4fed8d65e28a970e1c5cb33ce9c7e22e3de745e1b2ae37af051ef16aea3b/Parsley-1.3-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (0.36.2)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Installing collected packages: Parsley, piglet-templates, piglet\n",
            "Successfully installed Parsley-1.3 piglet-1.0.0 piglet-templates-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGeeJuNiCcM6"
      },
      "source": [
        "# !apt update && apt install xvfb\n",
        "# !pip install gym-notebook-wrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncha4jn7CdSw"
      },
      "source": [
        "from collections import Container, Counter, Iterator, deque"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hHa3eaRajfdh",
        "outputId": "46b42984-2d0c-4804-b8f5-a3be783e47e7"
      },
      "source": [
        "'''\n",
        "env.reset()\n",
        "img = plt.imshow(env.render('rgb_array')) # only call this once\n",
        "for _ in range(500):\n",
        "    img.set_data(env.render('rgb_array')) # just update the data\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    action = env.action_space.sample()\n",
        "    env.step(action)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nenv.reset()\\nimg = plt.imshow(env.render('rgb_array')) # only call this once\\nfor _ in range(500):\\n    img.set_data(env.render('rgb_array')) # just update the data\\n    display.display(plt.gcf())\\n    display.clear_output(wait=True)\\n    action = env.action_space.sample()\\n    env.step(action)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwHlnE8PjnYR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pnUGSNMa18j"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPool2D, Input, Flatten\n",
        "from tensorflow.keras.losses import mse, mae\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-beHqVWmkWls",
        "outputId": "a8642393-b570-4212-b91c-e9c47a5a4870"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
        "# Build a graph.\n",
        "c= tf.compat.v1.placeholder(dtype=tf.float32)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "sess = tf.compat.v1.Session()\n",
        "\n",
        "# Evaluate the tensor `c`.\n",
        "print(sess.run(c, feed_dict={c:2.571}))\n",
        "\n",
        "print(sess.run(c, feed_dict={c:3.14157}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.571\n",
            "3.14157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUXZSMwe54Ti"
      },
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    y_pred = self(x , training= True)\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.compiled_loss(y, y_pred)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y38OO1AnYsCa"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, input_shape, output_shape, alpha):\n",
        "    self.input_shape = input_shape\n",
        "    self.output_shape = output_shape\n",
        "    self.alpha = alpha\n",
        "    self.optimizer = RMSprop(self.alpha)\n",
        "    self.sample_weights = []\n",
        "\n",
        "  def call_layers(self):\n",
        "    x =  Input(shape=self.input_shape)\n",
        "    h1 = Conv2D(32, (5,5), strides=2, activation='relu', data_format='channels_first')(x)\n",
        "    h2 = Conv2D(64, (3,3), strides=2, activation='relu', data_format='channels_first')(h1)\n",
        "    f = Flatten()(h2)\n",
        "    d1 = Dense(256, activation='relu')(f)\n",
        "    pi = Dense(self.output_shape, activation='softmax')(d1)\n",
        "    val = Dense(1, activation='linear')(d1)\n",
        "    #self.model = Model(inputs=inputs, outputs=[actor, critic])\n",
        "    self.actor = Model(inputs=x, outputs=pi)\n",
        "    self.critic = Model(inputs=x,output=val)\n",
        "    #self.model.compile(loss=loss_function, optimizer=self.optimizer(self.alpha), metrics=['accuracy'])\n",
        "  \n",
        "  \n",
        "  def model_fit(self, loss_fn, wts, model=''):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.actor_loss_function(wts)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "  \n",
        "  def critic_loss_function(y_pred, y_true):\n",
        "    return K.mean((y_pred - y_true)**2)\n",
        "\n",
        "\n",
        "  def actor_loss_function(self, advantages):\n",
        "    def entropy_loss(y_true, y_pred):\n",
        "      return K.sum(advantages * (-y_true*K.log(y_pred)), axis=1)\n",
        "    return entropy_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t46itvBGDt5"
      },
      "source": [
        "class Agent(Model):\n",
        "  def __init__(self, memory_capacity, state_space=(84,84,4), action_space=6):\n",
        "    super().__init__(input_shape=(1,)+state_space, output_shape=action_space, alpha=0.001)\n",
        "    self.max_length = max_length\n",
        "    self.state_space = state_space\n",
        "    self.action_space = action_space\n",
        "    self.gamma = 0.99\n",
        "    self.states = deque(max_length)\n",
        "    self.actions = deque(max_length)\n",
        "    self.rewards = deque(max_length)\n",
        "    self.memory_counter = 0\n",
        "    #self.nn = Model(input_shape=(1,)+state_space, output_shape=action_space, alpha=0.001)\n",
        "    self.call_layers()\n",
        "    #self.actor.compile(loss=actor_loss_function(self.advantage_pl), optimizer=self.optimizer(self.alpha))\n",
        "    #self.critic.compile(loss=critic_loss_function, optimizer=self.optimizer(self.alpha), metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "  \n",
        "  def remember(self, state, action, reward, done):\n",
        "    self.states.append(state)\n",
        "    one_hot_encoded_actions = np.zeros((action_space,))\n",
        "    one_hot_encoded_actions[action]=1\n",
        "    self.actions.append(one_hot_encoded_actions)\n",
        "    self.rewards.append(reward)\n",
        "    self.memory_counter += 1\n",
        "\n",
        "  def sample_memory(self, batch_size):\n",
        "    return np.random.choice(self.memory_counter, batch_size=batch_size)\n",
        "  \n",
        "  def act(self, states):\n",
        "    pred_actions = self.actor.predict(states)[0]\n",
        "    action = np.random.choice(self.action_space, 1, p = pred_actions)\n",
        "    return action\n",
        "  \n",
        "  def replay(self):\n",
        "    discounted_rewards = np.array(discount_rewards(self.rewards))\n",
        "    self.actions = np.array(self.actions)\n",
        "    self.states = np.array(self.states)\n",
        "    value_fn = self.critic.predict(self.states)[0]\n",
        "    self.advantages = discounted_rewards - value_fn\n",
        "    self.actor.train_on_batch(x=self.states, y=self.actions)\n",
        "    self.critic.train_on_batch(x=self.states, discounted_rewards)\n",
        "\n",
        "  def discount_rewards(self, rewards):\n",
        "    dr = []\n",
        "    cumulative_rewards = 0\n",
        "    for i in range(reversed(rewards)):\n",
        "        cumulative_rewards = cumulative_rewards*gamma + rewards[i]\n",
        "        dr.append(cumulative_rewards)\n",
        "    dr = np.asarray(dr,dtype='float32')\n",
        "    normalized_dr = (dr - np.mean(dr))/np.std(dr)\n",
        "    return normalized_dr.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5co8di1jJtob",
        "outputId": "b72b03f7-754b-4a75-edf2-b94a6c7d0920"
      },
      "source": [
        "def func1(x,y):\n",
        "  x = 3*x + 5\n",
        "  y= 2*y + 10\n",
        "  c = 2\n",
        "  def entropy(a):\n",
        "    return a*np.log(a) / c\n",
        "  return entropy(x), entropy(y)\n",
        "\n",
        "func1(np.random.randn(),np.random.randn())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.5086987739053948, 14.491824020777704)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAyrG-U-_-N5"
      },
      "source": [
        "class EnvWrapper:\n",
        "  def __init__(self, game='SpaceInvaders-v0', skip_frames=4, frame_width=84, frame_height=84):\n",
        "    self.skip_frames = skip_frames\n",
        "    #self.num_frames = num_frames\n",
        "    self.env = gym.make(game)\n",
        "    self.frame_width = frame_width\n",
        "    self.frame_height = frame_height\n",
        "    self.state = None\n",
        "    self.action_space = [i for i in range(self.env.action_space.n)]\n",
        "  \n",
        "  def preprocess(self, img, start=False):\n",
        "    grayscale = img.astype(np.float32).mean(axis=2)\n",
        "    reshaped_grayscale = grayscale.reshape(1, img.shape[0], img.shape[1], 1)\n",
        "    if start or self.state is None:\n",
        "      self.state = np.repeat(reshaped_grayscale, self.skip_frames, axis=3)\n",
        "    else:\n",
        "      self.state = np.append(reshaped_grayscale, self.state[:,:,:,:self.skip_frames-1], axis=3)\n",
        "  \n",
        "  def reset(self):\n",
        "    self.preprocess(self.env.reset(), start=True)\n",
        "\n",
        "  def render(self, num_steps):\n",
        "    img = plt.imshow(self.env.render('rgb_array'))\n",
        "    for _ in range(num_steps):\n",
        "      img.set_data(env.render('rgb_array')) # just update the data\n",
        "      display.display(plt.gcf())\n",
        "      display.clear_output(wait=True)\n",
        "      action = env.action_space.sample()\n",
        "      env.step(action)\n",
        "\n",
        "  def step(self, action_idx):\n",
        "    action = self.action_space[action_idx]\n",
        "    prev_s = None\n",
        "    total_rewards = 0\n",
        "    for _ in range(0, self.skip_frames):\n",
        "      s, r, done, info = self.env.step(action)\n",
        "      total_rewards += r\n",
        "      if done:\n",
        "        break\n",
        "      prev_s = s\n",
        "    if prev_s is not None:\n",
        "      s = np.maximum.reduce([s, prev_s])\n",
        "    self.preprocess(s)\n",
        "    return total_rewards, done, info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9UOdtXTUsxj",
        "outputId": "5a947fda-9848-4be0-93ce-d6824b092be8"
      },
      "source": [
        "env1 = EnvWrapper()\n",
        "state = env1.reset()\n",
        "num_episodes = 100\n",
        "time_steps, done = 0, False\n",
        "episodic_reward = []\n",
        "#agent = Agent()\n",
        "for e in range(num_episodes):\n",
        "  state = env1.reset()\n",
        "  accum_rewards = 0\n",
        "  while not done:\n",
        "    action = env1.agent.act(state) #agent.act(state)\n",
        "    print(action)\n",
        "    reward, done, info = env1.step(action)\n",
        "    accum_rewards += reward\n",
        "    #agent.remember(new_state, reward, done, info)\n",
        "    episodic_reward.append(accum_rewards)\n",
        "    state = env1.state\n",
        "    print(reward)\n",
        "    if done:\n",
        "      break\n",
        "  #agent.train_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "30.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "5.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "15.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "0\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "3\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "4\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "2\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "5\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "1\n",
            "(1, 210, 160, 1)\n",
            "0.0\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n",
            "(1, 210, 160, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HJRnwIc-bHo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}